storage_account_name = "venkatnormalblobstorage"
storage_account_access_key = "kutYGTCjtItDJV3Ga91e3S/dDrDycimlO71n5bEb7OsjMfx6T1LlFq6yGMc6aaZUTunjdII0CyiDv6eEQw8jBA=="
file_location = "wasbs://files@venkatnormalblobstorage.blob.core.windows.net/employees.csv"
file_type = "csv"  
spark.conf.set(
  "fs.azure.account.key."+storage_account_name+".blob.core.windows.net",
  storage_account_access_key)
df = spark.read.format(file_type).option("inferSchema", "true").option("header","true").load(file_location)
df = df.filter(df.sal > 5000)

jdbcHostname = "onpremazuresql.database.windows.net"
jdbcDatabase = "onpremazuresql"
username="onpremazuresql"
password="December@2p019"
jdbcPort = 1433
jdbcUrl = "jdbc:sqlserver://{0}:{1};database={2};user={3};password={4}".format(jdbcHostname, jdbcPort, jdbcDatabase, username, password)
#display(df)
table="emps"
df.write.mode("append").format("jdbc").option("url", jdbcUrl).option("dbtable", table).option("driver", "com.microsoft.sqlserver.jdbc.SQLServerDriver").save()



--mounting dbfs
dbutils.fs.mount(source="wasbs://files@databrickspocjan29.blob.core.windows.net",
                 mount_point="/mnt/files",
                 extra_configs={"fs.azure.account.key.databrickspocjan29.blob.core.windows.net": "uUuOmfLvAONfUUWQkkBOR0DUV5OgtlNYhLZOfGMbSn5E6EK7gLQ+s4VYncSgav0sTFmz+f8ygZkJ+RS7KbexGA=="})
file_type = "csv"
df=spark.read.format("csv").option("inferSchema", "true").option("header","true").load("/mnt/files/emp.csv")
df=df.filter(df.sal > 5000)
display(df)
